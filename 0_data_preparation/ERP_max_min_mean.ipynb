{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "bb8c2423",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install netCDF4\n",
    "import os\n",
    "from netCDF4 import Dataset\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.signal import find_peaks\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "186b79f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "当前正在处理第0个文件\n",
      "当前正在处理第1000个文件\n",
      "当前正在处理第2000个文件\n",
      "当前正在处理第3000个文件\n",
      "当前正在处理第4000个文件\n",
      "当前正在处理第5000个文件\n",
      "当前正在处理第6000个文件\n",
      "当前正在处理第7000个文件\n",
      "当前正在处理第8000个文件\n",
      "当前正在处理第9000个文件\n",
      "当前正在处理第10000个文件\n",
      "当前正在处理第11000个文件\n",
      "当前正在处理第12000个文件\n",
      "当前正在处理第13000个文件\n",
      "当前正在处理第14000个文件\n",
      "当前正在处理第15000个文件\n",
      "当前正在处理第16000个文件\n",
      "当前正在处理第17000个文件\n",
      "当前正在处理第18000个文件\n",
      "当前正在处理第19000个文件\n",
      "当前正在处理第20000个文件\n",
      "当前正在处理第21000个文件\n",
      "当前正在处理第22000个文件\n",
      "当前正在处理第23000个文件\n",
      "当前正在处理第24000个文件\n",
      "当前正在处理第25000个文件\n",
      "当前正在处理第26000个文件\n",
      "当前正在处理第27000个文件\n",
      "当前正在处理第28000个文件\n",
      "当前正在处理第29000个文件\n",
      "当前正在处理第30000个文件\n",
      "当前正在处理第31000个文件\n",
      "当前正在处理第32000个文件\n",
      "当前正在处理第33000个文件\n",
      "当前正在处理第34000个文件\n",
      "当前正在处理第35000个文件\n",
      "当前正在处理第36000个文件\n",
      "当前正在处理第37000个文件\n",
      "当前正在处理第38000个文件\n",
      "当前正在处理第39000个文件\n",
      "当前正在处理第40000个文件\n",
      "当前正在处理第41000个文件\n",
      "当前正在处理第42000个文件\n",
      "当前正在处理第43000个文件\n",
      "当前正在处理第44000个文件\n",
      "当前正在处理第45000个文件\n",
      "当前正在处理第46000个文件\n",
      "当前正在处理第47000个文件\n",
      "当前正在处理第48000个文件\n",
      "当前正在处理第49000个文件\n",
      "当前正在处理第50000个文件\n",
      "当前正在处理第51000个文件\n",
      "当前正在处理第52000个文件\n",
      "当前正在处理第53000个文件\n",
      "当前正在处理第54000个文件\n",
      "当前正在处理第55000个文件\n",
      "当前正在处理第56000个文件\n",
      "当前正在处理第57000个文件\n",
      "当前正在处理第58000个文件\n",
      "当前正在处理第59000个文件\n",
      "当前正在处理第60000个文件\n",
      "当前正在处理第61000个文件\n",
      "当前正在处理第62000个文件\n",
      "当前正在处理第63000个文件\n",
      "当前正在处理第64000个文件\n",
      "当前正在处理第65000个文件\n",
      "当前正在处理第66000个文件\n",
      "当前正在处理第67000个文件\n",
      "当前正在处理第68000个文件\n",
      "当前正在处理第69000个文件\n",
      "当前正在处理第70000个文件\n",
      "当前正在处理第71000个文件\n",
      "当前正在处理第72000个文件\n",
      "当前正在处理第73000个文件\n",
      "当前正在处理第74000个文件\n",
      "当前正在处理第75000个文件\n",
      "当前正在处理第76000个文件\n",
      "当前正在处理第77000个文件\n",
      "当前正在处理第78000个文件\n",
      "当前正在处理第79000个文件\n",
      "当前正在处理第80000个文件\n",
      "当前正在处理第81000个文件\n",
      "当前正在处理第82000个文件\n",
      "当前正在处理第83000个文件\n",
      "当前正在处理第84000个文件\n",
      "当前正在处理第85000个文件\n",
      "当前正在处理第86000个文件\n",
      "当前正在处理第87000个文件\n",
      "当前正在处理第88000个文件\n",
      "当前正在处理第89000个文件\n",
      "当前正在处理第90000个文件\n",
      "当前正在处理第91000个文件\n",
      "当前正在处理第92000个文件\n",
      "当前正在处理第93000个文件\n",
      "当前正在处理第94000个文件\n",
      "当前正在处理第95000个文件\n",
      "当前正在处理第96000个文件\n",
      "当前正在处理第97000个文件\n",
      "当前正在处理第98000个文件\n",
      "当前正在处理第99000个文件\n",
      "保存完成。\n"
     ]
    }
   ],
   "source": [
    "# 设置根目录（换成你自己的路径）  \n",
    "root_dir = r'D:\\\\A_sem2\\\\ERP\\\\Simulation\\\\lhs_data\\\\lhs_data'  \n",
    "n_files = 100000  \n",
    "result = []\n",
    "\n",
    "\n",
    "\n",
    "for i in range(n_files):\n",
    "    nc_path = os.path.join(root_dir, f'{i}.nc')\n",
    "    \n",
    "    with Dataset(nc_path, 'r') as ds:\n",
    "            # 取TSA并压缩为1D\n",
    "            TSA = ds.variables['TSA'][:].squeeze()       # 保证shape=(N,)\n",
    "            # # 若有填充值做异常剔除（以1e36为例，可按实际需要修改）\n",
    "            # TSA = TSA[TSA < 1e35]\n",
    "\n",
    "            # 找最大峰值并求平均\n",
    "            peaks_max, properties = find_peaks(TSA, prominence=1)\n",
    "            TSA_peak_max = TSA[peaks_max]\n",
    "            TSA_peak_max_mean = TSA_peak_max.mean()\n",
    "\n",
    "            # 找最小峰值并求平均\n",
    "            peaks_min, properties = find_peaks(-TSA, prominence=1)\n",
    "            TSA_peak_min = TSA[peaks_min]\n",
    "            TSA_peak_min_mean = TSA_peak_min.mean()\n",
    "\n",
    "            # 求平均值\n",
    "            TSA_mean = TSA.mean()\n",
    "        \n",
    "            result.append([TSA_peak_max_mean, TSA_peak_min_mean,TSA_mean])\n",
    "\n",
    "            if i % 1000 == 0:\n",
    "                print(f'当前正在处理第{i}个文件')\n",
    "            \n",
    "\n",
    "# 写入Excel\n",
    "df = pd.DataFrame(result, columns=['TSA_peak_max_mean', 'TSA_peak_min_mean', 'TSA_mean'])\n",
    "df.to_excel('TSA_max_min_mean.xlsx', index=False)\n",
    "print('保存完成。')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acd16a7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 打开 NetCDF 文件\n",
    "nc_file = 'D:\\\\A_sem2\\\\ERP\\\\Simulation\\\\lhs_data\\\\lhs_data\\\\0.nc'\n",
    "ds = Dataset(nc_file, 'r')\n",
    "\n",
    "# # 查看所有变量\n",
    "# print(ds.variables.keys())\n",
    "\n",
    "# 读取时间变量\n",
    "time = ds.variables['time'][:]  # \n",
    "# 读取某个变量\n",
    "TSA = ds.variables['TSA'][:]  #\n",
    "\n",
    "# 读取属性\n",
    "# print(TSA)\n",
    "print(TSA.shape)\n",
    "# 关闭文件\n",
    "ds.close()\n",
    "\n",
    "TSA = TSA.squeeze() \n",
    "# 一般来说，你可以适当设置prominence参数，排除小波动的“虚假峰值”\n",
    "peaks, properties = find_peaks(TSA, prominence=1)\n",
    "peak_TSA = TSA[peaks]\n",
    "peak_time = time[peaks]\n",
    "print(peak_TSA)\n",
    "print(peak_time)\n",
    "\n",
    "peak_TSA_mean = peak_TSA.mean() # 注意要加括号！\n",
    "print(peak_TSA_mean)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
